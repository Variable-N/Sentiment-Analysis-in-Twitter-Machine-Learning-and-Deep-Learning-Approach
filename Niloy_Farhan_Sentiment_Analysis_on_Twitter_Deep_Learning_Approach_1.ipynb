{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Niloy Farhan Sentiment Analysis on Twitter: Deep Learning Approach 1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RP-h6PGtj0r4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis on Twitter: Deep Learning Approach 1\n",
        "Author: Niloy Farhan\n",
        "\n",
        "Model Description:\n",
        "\n",
        "Embedding Layer -> Spatial Dropout 1d -> Bidirectional LSTM Layer -> Dense(300) Layer -> Softmax Activation Layer\n",
        "\n",
        "Best Score after pre-processing (Own Embedding):\n",
        "\n",
        "72% Accuracy"
      ],
      "metadata": {
        "id": "ytZd4KijjiUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "SkyZSsLqjumu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iiVYRhkxgnbs"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, GRU\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers import Embedding\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from keras.layers import Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import resample\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-55qy6eFptLZ",
        "outputId": "20ab4617-4e4a-4ba8-a345-42df21245f26"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TPU INITIALIZATION"
      ],
      "metadata": {
        "id": "RP-h6PGtj0r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WICa3GNZj0Oa",
        "outputId": "7401dc54-69d7-4dd4-d34d-c90a4b9976ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.8.0\n",
            "Running on TPU  ['10.86.121.202:8470']\n",
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.86.121.202:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.86.121.202:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading"
      ],
      "metadata": {
        "id": "7p3OpVCtj60s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2013dev-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df1 = df1.drop(labels=[\"id\"], axis = 1)\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2013test-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df2 = df2.drop(labels=[\"id\"], axis = 1)\n",
        "df3 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2013train-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df3 = df3.drop(labels=[\"id\"], axis = 1)\n",
        "df4 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2014sarcasm-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df4 = df4.drop(labels=[\"id\"], axis = 1)\n",
        "df5 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2015test-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df5 = df5.drop(labels=[\"id\"], axis = 1)\n",
        "df6 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2015train-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df6 = df6.drop(labels=[\"id\"], axis = 1)\n",
        "df7 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2016dev-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df7 = df7.drop(labels=[\"id\"], axis = 1)\n",
        "df8 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2016devtest-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df8 = df8.drop(labels=[\"id\"], axis = 1)\n",
        "df9 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2016train-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df9 = df9.drop(labels=[\"id\"], axis = 1)"
      ],
      "metadata": {
        "id": "efQGGX1Zjwhz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9]).reset_index(drop=True)\n",
        "df = pd.concat([df3,df5,df8,df9]).reset_index(drop=True)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "32Eoqq_OkuTn",
        "outputId": "0bde2441-1cd3-45a9-c83e-f09f02cdd0fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      sentiment                                             tweets\n",
              "0      positive  Gas by my house hit $3.39!!!! I\\u2019m going t...\n",
              "1      negative  Theo Walcott is still shit\\u002c watch Rafa an...\n",
              "2      negative  its not that I\\u2019m a GSP fan\\u002c i just h...\n",
              "3      negative  Iranian general says Israel\\u2019s Iron Dome c...\n",
              "4       neutral  Tehran\\u002c Mon Amour: Obama Tried to Establi...\n",
              "...         ...                                                ...\n",
              "19937  positive  @Racalto_SK ok good to know. Punting at MetLif...\n",
              "19938   neutral  everyone who sat around me at metlife was so a...\n",
              "19939   neutral  what giants or niners fans would wanna go to t...\n",
              "19940  positive  Anybody want a ticket for tomorrow Colombia vs...\n",
              "19941   neutral  Mendez told me he'd drive me to MetLife on Sun...\n",
              "\n",
              "[19942 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cf5634b-56fd-4f94-af0e-9f3b8ce15e3c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>Gas by my house hit $3.39!!!! I\\u2019m going t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>Theo Walcott is still shit\\u002c watch Rafa an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>its not that I\\u2019m a GSP fan\\u002c i just h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>Iranian general says Israel\\u2019s Iron Dome c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Tehran\\u002c Mon Amour: Obama Tried to Establi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19937</th>\n",
              "      <td>positive</td>\n",
              "      <td>@Racalto_SK ok good to know. Punting at MetLif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19938</th>\n",
              "      <td>neutral</td>\n",
              "      <td>everyone who sat around me at metlife was so a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19939</th>\n",
              "      <td>neutral</td>\n",
              "      <td>what giants or niners fans would wanna go to t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19940</th>\n",
              "      <td>positive</td>\n",
              "      <td>Anybody want a ticket for tomorrow Colombia vs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19941</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Mendez told me he'd drive me to MetLife on Sun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19942 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cf5634b-56fd-4f94-af0e-9f3b8ce15e3c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cf5634b-56fd-4f94-af0e-9f3b8ce15e3c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cf5634b-56fd-4f94-af0e-9f3b8ce15e3c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balancing the dataset\n",
        "\n",
        "Our dataset is unbalanced when it comes to negative sentiment. So, we will resample to balance it."
      ],
      "metadata": {
        "id": "k3arkUB5m_xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCchEDzSm1tT",
        "outputId": "2c9e8f9b-49ab-47d3-a492-7d1b478fc489"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    8689\n",
              "neutral     8255\n",
              "negative    2998\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_balance(data):\n",
        "    data_positive = data[(data['sentiment']=='positive')]\n",
        "    data_neutral = data[(data['sentiment']=='neutral')]\n",
        "    data_negative = data[(data['sentiment']=='negative')]\n",
        "    # data['sentiment'].value_counts()[2]\n",
        "    # data_positive_downsampled = resample(data_positive, replace = True, n_samples = 6000, random_state = 42)\n",
        "    # data_neutral_downsampled = resample(data_neutral, replace = True, n_samples =  data['sentiment'].value_counts()[0], random_state = 42)\n",
        "    data_negative_upsampled = resample(data_negative, replace = True, n_samples =  data['sentiment'].value_counts()[1], random_state = 42)\n",
        "    balanced_dataset = pd.concat([data_positive,data_neutral,data_negative_upsampled]).reset_index(drop=True)\n",
        "    return balanced_dataset"
      ],
      "metadata": {
        "id": "aaos23PjnO73"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset_balance(df)\n",
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS6f5SAcnsZ7",
        "outputId": "18ee6168-4c8a-41a6-c570-84833b2618c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    8689\n",
              "neutral     8255\n",
              "negative    8255\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRE-PROCESSING\n",
        "\n",
        "1. removed link\n",
        "2. removed linebreaks\n",
        "3. removed extra spaces\n",
        "4. removed punctuation\n",
        "5. removed stopwords\n",
        "6. lowercased the tweet\n",
        "7. extracted hashtags and added at the end of the sentence\n",
        "8. extracted mentions and added at the end of the sentence"
      ],
      "metadata": {
        "id": "VyrqlTNXl9i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_encoder(x):\n",
        "    if x == 'positive': return 2\n",
        "    elif x == 'negative': return 0\n",
        "    else: return 1\n",
        "\n",
        "def clean_text(x):\n",
        "    x = re.sub(r'https?://\\S+', '', x) \n",
        "    x = re.sub(r'#\\w+', '', x) \n",
        "    x = re.sub(r'@\\w+', '', x) \n",
        "    x = re.sub(r'\\n',' ',x) \n",
        "    x = re.sub('\\s+', ' ', x).strip()\n",
        "    x = re.sub('\\.','',x) \n",
        "    for p in string.punctuation:\n",
        "        x = re.sub('\\{}'.format(p),'',x)\n",
        "    return x.lower()\n",
        "def find_hashtags(tweet):\n",
        "    return \" \".join([match.group(0)[1:] for match in re.finditer(r\"#\\w+\", tweet)]) or ''\n",
        "\n",
        "def find_mentions(tweet):\n",
        "    return \" \".join([match.group(0)[1:] for match in re.finditer(r\"@\\w+\", tweet)]) or ''\n",
        "\n",
        "def pre_process_text(df):\n",
        "    stop = stopwords.words('english')\n",
        "    df['clean_tweet'] = df['tweets'].apply(lambda x: clean_text(x))\n",
        "    df['hashtags'] = df['tweets'].apply(lambda x: find_hashtags(x))\n",
        "    df['mentions'] = df['tweets'].apply(lambda x: find_mentions(x))\n",
        "    df['sentiment'] = df['sentiment'].apply(lambda x: label_encoder(x))\n",
        "    df['clean_tweet_without_stopword'] = df['clean_tweet'].apply(lambda x:' '.join([word for word in x.split() if word not in stop]))\n",
        "    df['final'] = df['clean_tweet_without_stopword']+\" \"+df['hashtags']+\" \"+df['mentions']\n",
        "    # df['clean_tweet']+\" \"+\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "1ANPZDKDl9QD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset = pre_process_text(df)"
      ],
      "metadata": {
        "id": "KjxYRndNpeny"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "IZpR7ouEp2H9",
        "outputId": "14810bb2-3995-4cdd-95d0-fbfb0dc3af05"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sentiment                                             tweets  \\\n",
              "25194          0  One of my Magic Mike XXL co-workers and the co...   \n",
              "25195          0  Sreven Taylor will look pretty daft after the ...   \n",
              "25196          0  i hope justin's concert thursday gets cancelle...   \n",
              "25197          0  About as much interest in today as I do in the...   \n",
              "25198          0  @Becker_Boris It\\u2019s almost 2 am in BKK but...   \n",
              "\n",
              "                                             clean_tweet hashtags  \\\n",
              "25194  one of my magic mike xxl coworkers and the coo...            \n",
              "25195  sreven taylor will look pretty daft after the ...            \n",
              "25196  i hope justins concert thursday gets cancelled...            \n",
              "25197  about as much interest in today as i do in the...     zero   \n",
              "25198  itu2019s almost 2 am in bkk but i canu2019t sl...            \n",
              "\n",
              "           mentions                       clean_tweet_without_stopword  \\\n",
              "25194                one magic mike xxl coworkers coordinator premi...   \n",
              "25195                sreven taylor look pretty daft mackems win tom...   \n",
              "25196                hope justins concert thursday gets cancelled b...   \n",
              "25197                              much interest today rugby world cup   \n",
              "25198  Becker_Boris  itu2019s almost 2 bkk canu2019t sleep game isn...   \n",
              "\n",
              "                                                   final  \n",
              "25194  one magic mike xxl coworkers coordinator premi...  \n",
              "25195  sreven taylor look pretty daft mackems win tom...  \n",
              "25196  hope justins concert thursday gets cancelled b...  \n",
              "25197          much interest today rugby world cup zero   \n",
              "25198  itu2019s almost 2 bkk canu2019t sleep game isn...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66fe3b7a-0699-4426-b6d8-c552b2f4a19c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweets</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>mentions</th>\n",
              "      <th>clean_tweet_without_stopword</th>\n",
              "      <th>final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25194</th>\n",
              "      <td>0</td>\n",
              "      <td>One of my Magic Mike XXL co-workers and the co...</td>\n",
              "      <td>one of my magic mike xxl coworkers and the coo...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>one magic mike xxl coworkers coordinator premi...</td>\n",
              "      <td>one magic mike xxl coworkers coordinator premi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25195</th>\n",
              "      <td>0</td>\n",
              "      <td>Sreven Taylor will look pretty daft after the ...</td>\n",
              "      <td>sreven taylor will look pretty daft after the ...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>sreven taylor look pretty daft mackems win tom...</td>\n",
              "      <td>sreven taylor look pretty daft mackems win tom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25196</th>\n",
              "      <td>0</td>\n",
              "      <td>i hope justin's concert thursday gets cancelle...</td>\n",
              "      <td>i hope justins concert thursday gets cancelled...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>hope justins concert thursday gets cancelled b...</td>\n",
              "      <td>hope justins concert thursday gets cancelled b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25197</th>\n",
              "      <td>0</td>\n",
              "      <td>About as much interest in today as I do in the...</td>\n",
              "      <td>about as much interest in today as i do in the...</td>\n",
              "      <td>zero</td>\n",
              "      <td></td>\n",
              "      <td>much interest today rugby world cup</td>\n",
              "      <td>much interest today rugby world cup zero</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25198</th>\n",
              "      <td>0</td>\n",
              "      <td>@Becker_Boris It\\u2019s almost 2 am in BKK but...</td>\n",
              "      <td>itu2019s almost 2 am in bkk but i canu2019t sl...</td>\n",
              "      <td></td>\n",
              "      <td>Becker_Boris</td>\n",
              "      <td>itu2019s almost 2 bkk canu2019t sleep game isn...</td>\n",
              "      <td>itu2019s almost 2 bkk canu2019t sleep game isn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66fe3b7a-0699-4426-b6d8-c552b2f4a19c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-66fe3b7a-0699-4426-b6d8-c552b2f4a19c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-66fe3b7a-0699-4426-b6d8-c552b2f4a19c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Longest sequence"
      ],
      "metadata": {
        "id": "KLAeChtdqK3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset['final'].apply(lambda x:len(str(x).split())).max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSftLvylqC_M",
        "outputId": "1e3b2f59-88e0-4491-f0a9-088eacea6e58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "689"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_NB_WORDS = 50000\n",
        "MAX_SEQUENCE_LENGTH = 750\n",
        "EMBEDDING_DIM = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(final_dataset['final'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPME0mIgV50A",
        "outputId": "157175f3-519c-4d6d-f853-cae07c7843c8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 38284 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = tokenizer.texts_to_sequences(final_dataset['final'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yzazgbqWcPv",
        "outputId": "40697fcf-066f-4088-fdaa-ee8663d4804a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (25199, 750)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data spliting"
      ],
      "metadata": {
        "id": "vlyKtaBmqX_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = pd.get_dummies(final_dataset['sentiment']).values\n",
        "print('Shape of label tensor:', Y.shape)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZdy8jVfqO5O",
        "outputId": "43ba280f-8b9e-4a17-8f62-63e3a48a304d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label tensor: (25199, 3)\n",
            "(22679, 750) (22679, 3)\n",
            "(2520, 750) (2520, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Model"
      ],
      "metadata": {
        "id": "6nIr30-Jri7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tpu_strategy.scope():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "  model.add(SpatialDropout1D(0.2))\n",
        "  model.add(Bidirectional(LSTM(300, dropout=0.2, recurrent_dropout=0.2)))\n",
        "  model.add(Dense(300, activation='relu'))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OweoglVfrgqu",
        "outputId": "61961e9d-1424-486d-f7c4-0d7e5a884064"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 750, 200)          10000000  \n",
            "                                                                 \n",
            " spatial_dropout1d_2 (Spatia  (None, 750, 200)         0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 600)              1202400   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 300)               180300    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,383,603\n",
            "Trainable params: 11,383,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "batch_size = 32*tpu_strategy.num_replicas_in_sync\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=2, min_delta=0.0001)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc6GhjKisMMD",
        "outputId": "9aa5ad13-66b4-4c98-d73d-8c864aa3eb48"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "80/80 [==============================] - 107s 1s/step - loss: 0.9191 - accuracy: 0.5405 - val_loss: 0.7119 - val_accuracy: 0.6812\n",
            "Epoch 2/25\n",
            "80/80 [==============================] - 79s 987ms/step - loss: 0.4656 - accuracy: 0.8116 - val_loss: 0.6207 - val_accuracy: 0.7315\n",
            "Epoch 3/25\n",
            "80/80 [==============================] - 79s 985ms/step - loss: 0.2185 - accuracy: 0.9184 - val_loss: 0.6996 - val_accuracy: 0.7478\n",
            "Epoch 4/25\n",
            "80/80 [==============================] - 79s 986ms/step - loss: 0.1121 - accuracy: 0.9613 - val_loss: 0.8139 - val_accuracy: 0.7434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Data score"
      ],
      "metadata": {
        "id": "gTCZl4K6zAKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accr = model.evaluate(X_test,Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJegvDb5tZTn",
        "outputId": "651a4730-3225-4668-f15d-6ce3dee97c42"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 8s 86ms/step - loss: 0.9239 - accuracy: 0.7187\n",
            "Test set\n",
            "  Loss: 0.924\n",
            "  Accuracy: 0.719\n"
          ]
        }
      ]
    }
  ]
}