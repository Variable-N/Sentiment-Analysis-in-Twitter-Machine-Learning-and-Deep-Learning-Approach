{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Niloy Farhan  Sentiment Analysis on Twitter: Deep Learning Approach 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis on Twitter: Deep Learning Approach 2\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "Author: Niloy Farhan\n",
        "\n",
        "Model Description:\n",
        "\n",
        "Glove Embedding Layer -> Bidirectional LSTM Layer -> Dense(300) Layer -> Softmax Activation Layer\n",
        "\n",
        "Best Score after pre-processing (Glove.840B.300D):\n",
        "\n",
        "81% Accuracy"
      ],
      "metadata": {
        "id": "kow6hZBYiYl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "SkyZSsLqjumu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiVYRhkxgnbs"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, GRU\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers import Embedding\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from keras.layers import Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import resample\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-55qy6eFptLZ",
        "outputId": "20074d23-904e-4539-dfbf-bc2479a940c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TPU INITIALIZATION"
      ],
      "metadata": {
        "id": "RP-h6PGtj0r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WICa3GNZj0Oa",
        "outputId": "1334a84c-7fba-47df-96a8-a586198a5880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.8.0\n",
            "Running on TPU  ['10.29.205.210:8470']\n",
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.29.205.210:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.29.205.210:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading"
      ],
      "metadata": {
        "id": "7p3OpVCtj60s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2013dev-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df1 = df1.drop(labels=[\"id\"], axis = 1)\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2013test-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df2 = df2.drop(labels=[\"id\"], axis = 1)\n",
        "df3 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2013train-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df3 = df3.drop(labels=[\"id\"], axis = 1)\n",
        "df4 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2014sarcasm-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df4 = df4.drop(labels=[\"id\"], axis = 1)\n",
        "df5 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2015test-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df5 = df5.drop(labels=[\"id\"], axis = 1)\n",
        "df6 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2015train-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df6 = df6.drop(labels=[\"id\"], axis = 1)\n",
        "df7 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2016dev-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df7 = df7.drop(labels=[\"id\"], axis = 1)\n",
        "df8 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2016devtest-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df8 = df8.drop(labels=[\"id\"], axis = 1)\n",
        "df9 = pd.read_csv(\"/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/twitter-2016train-A.txt\", sep = '\\t', names = ['id','sentiment','tweets'])\n",
        "df9 = df9.drop(labels=[\"id\"], axis = 1)"
      ],
      "metadata": {
        "id": "efQGGX1Zjwhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9]).reset_index(drop=True)\n",
        "df = pd.concat([df8,df9]).reset_index(drop=True)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "32Eoqq_OkuTn",
        "outputId": "9d3e79ba-d274-4a87-cae0-eafacece0ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentiment                                             tweets\n",
              "0      neutral  @SeeMonterey LOST - Sony cell phone with holid...\n",
              "1      neutral  @PersonaSoda well yeah, that's third parties. ...\n",
              "2     negative  Sony rewards app is like a lot of 19 y.o femal...\n",
              "3      neutral  @fakethom Have android tab and don't use phone...\n",
              "4     positive  Finally I get my ps4 back I sent it to Sony ca...\n",
              "...        ...                                                ...\n",
              "7863  positive  @Racalto_SK ok good to know. Punting at MetLif...\n",
              "7864   neutral  everyone who sat around me at metlife was so a...\n",
              "7865   neutral  what giants or niners fans would wanna go to t...\n",
              "7866  positive  Anybody want a ticket for tomorrow Colombia vs...\n",
              "7867   neutral  Mendez told me he'd drive me to MetLife on Sun...\n",
              "\n",
              "[7868 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4861536-a288-463a-9da5-23741a28f4f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@SeeMonterey LOST - Sony cell phone with holid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@PersonaSoda well yeah, that's third parties. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>Sony rewards app is like a lot of 19 y.o femal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@fakethom Have android tab and don't use phone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>Finally I get my ps4 back I sent it to Sony ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7863</th>\n",
              "      <td>positive</td>\n",
              "      <td>@Racalto_SK ok good to know. Punting at MetLif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7864</th>\n",
              "      <td>neutral</td>\n",
              "      <td>everyone who sat around me at metlife was so a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7865</th>\n",
              "      <td>neutral</td>\n",
              "      <td>what giants or niners fans would wanna go to t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7866</th>\n",
              "      <td>positive</td>\n",
              "      <td>Anybody want a ticket for tomorrow Colombia vs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7867</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Mendez told me he'd drive me to MetLife on Sun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7868 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4861536-a288-463a-9da5-23741a28f4f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4861536-a288-463a-9da5-23741a28f4f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4861536-a288-463a-9da5-23741a28f4f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balancing the dataset\n",
        "\n",
        "Our dataset is unbalanced when it comes to negative sentiment. So, we will resample to balance it."
      ],
      "metadata": {
        "id": "k3arkUB5m_xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCchEDzSm1tT",
        "outputId": "2742061f-0854-4266-912e-3fa4efbc2990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    4011\n",
              "neutral     2682\n",
              "negative    1175\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_balance(data):\n",
        "    data_positive = data[(data['sentiment']=='positive')]\n",
        "    data_neutral = data[(data['sentiment']=='neutral')]\n",
        "    data_negative = data[(data['sentiment']=='negative')]\n",
        "    # data['sentiment'].value_counts()[2]\n",
        "    # data_positive_downsampled = resample(data_positive, replace = True, n_samples = 6000, random_state = 42)\n",
        "    data_neutral_downsampled = resample(data_neutral, replace = True, n_samples =  data['sentiment'].value_counts()[0], random_state = 42)\n",
        "    data_negative_upsampled = resample(data_negative, replace = True, n_samples =  data['sentiment'].value_counts()[0], random_state = 42)\n",
        "    balanced_dataset = pd.concat([data_positive,data_neutral_downsampled,data_negative_upsampled]).reset_index(drop=True)\n",
        "    return balanced_dataset"
      ],
      "metadata": {
        "id": "aaos23PjnO73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset_balance(df)\n",
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS6f5SAcnsZ7",
        "outputId": "49712872-f0e4-46a9-e503-e5af60b4e900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    4011\n",
              "neutral     4011\n",
              "negative    4011\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRE-PROCESSING\n",
        "\n",
        "1. removed link\n",
        "2. removed linebreaks\n",
        "3. removed extra spaces\n",
        "4. removed punctuation\n",
        "5. removed stopwords\n",
        "6. lowercased the tweet\n",
        "7. extracted hashtags and added at the end of the sentence\n",
        "8. extracted mentions and added at the end of the sentence"
      ],
      "metadata": {
        "id": "VyrqlTNXl9i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_encoder(x):\n",
        "    if x == 'positive': return 2\n",
        "    elif x == 'negative': return 0\n",
        "    else: return 1\n",
        "\n",
        "def clean_text(x):\n",
        "    x = re.sub(r'https?://\\S+', '', x) \n",
        "    x = re.sub(r'#\\w+', '', x) \n",
        "    x = re.sub(r'@\\w+', '', x) \n",
        "    x = re.sub(r'\\n',' ',x) \n",
        "    x = re.sub('\\s+', ' ', x).strip()\n",
        "    x = re.sub('\\.','',x) \n",
        "    for p in string.punctuation:\n",
        "        x = re.sub('\\{}'.format(p),'',x)\n",
        "    return x.lower()\n",
        "def find_hashtags(tweet):\n",
        "    return \" \".join([match.group(0)[1:] for match in re.finditer(r\"#\\w+\", tweet)]) or ''\n",
        "\n",
        "def find_mentions(tweet):\n",
        "    return \" \".join([match.group(0)[1:] for match in re.finditer(r\"@\\w+\", tweet)]) or ''\n",
        "\n",
        "def pre_process_text(df):\n",
        "    stop = stopwords.words('english')\n",
        "    df['clean_tweet'] = df['tweets'].apply(lambda x: clean_text(x))\n",
        "    df['hashtags'] = df['tweets'].apply(lambda x: find_hashtags(x))\n",
        "    df['mentions'] = df['tweets'].apply(lambda x: find_mentions(x))\n",
        "    df['sentiment'] = df['sentiment'].apply(lambda x: label_encoder(x))\n",
        "    df['clean_tweet_without_stopword'] = df['clean_tweet'].apply(lambda x:' '.join([word for word in x.split() if word not in stop]))\n",
        "    df['final'] = df['clean_tweet_without_stopword']+\" \"+df['hashtags']+\" \"+df['mentions']\n",
        "    # df['clean_tweet']+\" \"+\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "1ANPZDKDl9QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset = pre_process_text(df)"
      ],
      "metadata": {
        "id": "KjxYRndNpeny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "IZpR7ouEp2H9",
        "outputId": "4b814900-67f8-499e-bee7-c59f96f9d300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sentiment                                             tweets  \\\n",
              "12028          0  Why would you get married on Sept 11th?! If yo...   \n",
              "12029          0  May all the items saved for later in your Amaz...   \n",
              "12030          0  ok so i want to cry like, my expected delivery...   \n",
              "12031          0  De Rossi believes Juventus may struggle to cop...   \n",
              "12032          0  ICYMI: The 'failure' of Google+: A round-up of...   \n",
              "\n",
              "                                             clean_tweet      hashtags  \\\n",
              "12028  why would you get married on sept 11th if you ...                 \n",
              "12029  may all the items saved for later in your amaz...  moderncurses   \n",
              "12030  ok so i want to cry like my expected delivery ...                 \n",
              "12031  de rossi believes juventus may struggle to cop...                 \n",
              "12032  icymi the failure of google a roundup of inter...                 \n",
              "\n",
              "      mentions                       clean_tweet_without_stopword  \\\n",
              "12028           would get married sept 11th want special date ...   \n",
              "12029           may items saved later amazon basket increase p...   \n",
              "12030           ok want cry like expected delivery date ipad t...   \n",
              "12031           de rossi believes juventus may struggle cope s...   \n",
              "12032           icymi failure google roundup interesting techn...   \n",
              "\n",
              "                                                   final  \n",
              "12028  would get married sept 11th want special date ...  \n",
              "12029  may items saved later amazon basket increase p...  \n",
              "12030  ok want cry like expected delivery date ipad t...  \n",
              "12031  de rossi believes juventus may struggle cope s...  \n",
              "12032  icymi failure google roundup interesting techn...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-557682ab-9381-4de1-8d17-3384dd885803\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweets</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>mentions</th>\n",
              "      <th>clean_tweet_without_stopword</th>\n",
              "      <th>final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12028</th>\n",
              "      <td>0</td>\n",
              "      <td>Why would you get married on Sept 11th?! If yo...</td>\n",
              "      <td>why would you get married on sept 11th if you ...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>would get married sept 11th want special date ...</td>\n",
              "      <td>would get married sept 11th want special date ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12029</th>\n",
              "      <td>0</td>\n",
              "      <td>May all the items saved for later in your Amaz...</td>\n",
              "      <td>may all the items saved for later in your amaz...</td>\n",
              "      <td>moderncurses</td>\n",
              "      <td></td>\n",
              "      <td>may items saved later amazon basket increase p...</td>\n",
              "      <td>may items saved later amazon basket increase p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12030</th>\n",
              "      <td>0</td>\n",
              "      <td>ok so i want to cry like, my expected delivery...</td>\n",
              "      <td>ok so i want to cry like my expected delivery ...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>ok want cry like expected delivery date ipad t...</td>\n",
              "      <td>ok want cry like expected delivery date ipad t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12031</th>\n",
              "      <td>0</td>\n",
              "      <td>De Rossi believes Juventus may struggle to cop...</td>\n",
              "      <td>de rossi believes juventus may struggle to cop...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>de rossi believes juventus may struggle cope s...</td>\n",
              "      <td>de rossi believes juventus may struggle cope s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12032</th>\n",
              "      <td>0</td>\n",
              "      <td>ICYMI: The 'failure' of Google+: A round-up of...</td>\n",
              "      <td>icymi the failure of google a roundup of inter...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>icymi failure google roundup interesting techn...</td>\n",
              "      <td>icymi failure google roundup interesting techn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-557682ab-9381-4de1-8d17-3384dd885803')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-557682ab-9381-4de1-8d17-3384dd885803 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-557682ab-9381-4de1-8d17-3384dd885803');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Longest sentence"
      ],
      "metadata": {
        "id": "KLAeChtdqK3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset['final'].apply(lambda x:len(str(x).split())).max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSftLvylqC_M",
        "outputId": "43326018-cbea-435a-fd14-c8462cc78ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "689"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = pd.get_dummies(final_dataset['sentiment']).values\n",
        "print('Shape of label tensor:', Y.shape)\n",
        "X = final_dataset['final']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZdy8jVfqO5O",
        "outputId": "9e656f80-dc94-4bc7-c8b7-67017ba13983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label tensor: (12033, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data spliting"
      ],
      "metadata": {
        "id": "vlyKtaBmqX_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.8, random_state=42, shuffle = True)"
      ],
      "metadata": {
        "id": "UcZS8iZmqXXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing, Padding, Embedding"
      ],
      "metadata": {
        "id": "PTfhuDcnrYzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 800\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  \n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "metadata": {
        "id": "F-1Nuc4PqU87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_matrix(filepath, word_idx, embedding_dim):\n",
        "    vocab_size = len(word_idx) + 1  \n",
        "    emb = np.zeros((vocab_size, embedding_dim))\n",
        "    with open(filepath, 'r', encoding=\"utf8\") as f:\n",
        "        for i in f:\n",
        "            x = i.split(' ')\n",
        "            w, v = x[0], x[1:]\n",
        "            if w in word_idx:\n",
        "                emb[word_idx[w]] = np.asarray(v)[:embedding_dim]\n",
        "    return emb"
      ],
      "metadata": {
        "id": "OBXVGxthrSOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "embedding_matrix = create_embedding_matrix('/content/drive/MyDrive/Bracu/Spring2022/CSE440/Project/Dataset/glove.840B.300d.txt', tokenizer.word_index, embedding_dim)"
      ],
      "metadata": {
        "id": "1Ga_cS3ErWwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Model"
      ],
      "metadata": {
        "id": "6nIr30-Jri7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tpu_strategy.scope():\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(vocab_size, embedding_dim, \n",
        "                            weights=[embedding_matrix], \n",
        "                            input_length=maxlen, \n",
        "                            trainable=False))\n",
        "  model.add(Bidirectional(LSTM(300,activation='tanh', dropout=0.2, recurrent_dropout=0.2)))\n",
        "  model.add(Dense(300,activation = 'relu'))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OweoglVfrgqu",
        "outputId": "f301b5ea-e52d-402a-cbfe-6036e740a70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 800, 300)          4982100   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 600)              1442400   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               180300    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,605,703\n",
            "Trainable params: 1,623,603\n",
            "Non-trainable params: 4,982,100\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVPoZRmEMmxt",
        "outputId": "9c50e81f-cf76-4de0-881d-87a7682bfe8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9626, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "batch_size = 16*tpu_strategy.num_replicas_in_sync\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=2, min_delta=0.0001)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc6GhjKisMMD",
        "outputId": "c7cb9263-cc44-4fde-a7e5-d84874b7b2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "68/68 [==============================] - 44s 471ms/step - loss: 0.9099 - accuracy: 0.5572 - val_loss: 0.8561 - val_accuracy: 0.5909\n",
            "Epoch 2/25\n",
            "68/68 [==============================] - 24s 359ms/step - loss: 0.7791 - accuracy: 0.6494 - val_loss: 0.8206 - val_accuracy: 0.6220\n",
            "Epoch 3/25\n",
            "68/68 [==============================] - 24s 359ms/step - loss: 0.6822 - accuracy: 0.6935 - val_loss: 0.7596 - val_accuracy: 0.6739\n",
            "Epoch 4/25\n",
            "68/68 [==============================] - 24s 358ms/step - loss: 0.5675 - accuracy: 0.7630 - val_loss: 0.6453 - val_accuracy: 0.7165\n",
            "Epoch 5/25\n",
            "68/68 [==============================] - 24s 358ms/step - loss: 0.4564 - accuracy: 0.8146 - val_loss: 0.5891 - val_accuracy: 0.7591\n",
            "Epoch 6/25\n",
            "68/68 [==============================] - 24s 358ms/step - loss: 0.3595 - accuracy: 0.8549 - val_loss: 0.6130 - val_accuracy: 0.7664\n",
            "Epoch 7/25\n",
            "68/68 [==============================] - 24s 359ms/step - loss: 0.2831 - accuracy: 0.8916 - val_loss: 0.5773 - val_accuracy: 0.7934\n",
            "Epoch 8/25\n",
            "68/68 [==============================] - 24s 359ms/step - loss: 0.2095 - accuracy: 0.9225 - val_loss: 0.6287 - val_accuracy: 0.7850\n",
            "Epoch 9/25\n",
            "68/68 [==============================] - 24s 358ms/step - loss: 0.1590 - accuracy: 0.9427 - val_loss: 0.6737 - val_accuracy: 0.7965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Data score"
      ],
      "metadata": {
        "id": "gTCZl4K6zAKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accr = model.evaluate(X_test,Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJegvDb5tZTn",
        "outputId": "71f18241-7500-428d-edbe-3a5f2eb2757c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 8s 92ms/step - loss: 0.5904 - accuracy: 0.8168\n",
            "Test set\n",
            "  Loss: 0.590\n",
            "  Accuracy: 0.817\n"
          ]
        }
      ]
    }
  ]
}